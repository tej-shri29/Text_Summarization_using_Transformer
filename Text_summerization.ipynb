{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54ffb804-13e9-4a33-a78f-97e5d72c62aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ingle\\anaconda3\\envs\\forgery\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "791f20a1-b6a3-46d5-b423-8d9bd24d0a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"Inshorts Cleaned Data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4a82678-c2af-4bd6-99c0-7c8edf81989a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Headline', 'Short'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7be88aad-fb5d-4ccd-9857-690f6c80b934",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['Source ', 'Time ', 'Publish Date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f72eb6f-50d0-4972-b6fa-bc0864f6e732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Short</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 ex-bank officials booked for cheating bank o...</td>\n",
       "      <td>The CBI on Saturday booked four former officia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Supreme Court to go paperless in 6 months: CJI</td>\n",
       "      <td>Chief Justice JS Khehar has said the Supreme C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>At least 3 killed, 30 injured in blast in Sylh...</td>\n",
       "      <td>At least three people were killed, including a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why has Reliance been barred from trading in f...</td>\n",
       "      <td>Mukesh Ambani-led Reliance Industries (RIL) wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Was stopped from entering my own studio at Tim...</td>\n",
       "      <td>TV news anchor Arnab Goswami has said he was t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  \\\n",
       "0  4 ex-bank officials booked for cheating bank o...   \n",
       "1     Supreme Court to go paperless in 6 months: CJI   \n",
       "2  At least 3 killed, 30 injured in blast in Sylh...   \n",
       "3  Why has Reliance been barred from trading in f...   \n",
       "4  Was stopped from entering my own studio at Tim...   \n",
       "\n",
       "                                               Short  \n",
       "0  The CBI on Saturday booked four former officia...  \n",
       "1  Chief Justice JS Khehar has said the Supreme C...  \n",
       "2  At least three people were killed, including a...  \n",
       "3  Mukesh Ambani-led Reliance Industries (RIL) wa...  \n",
       "4  TV news anchor Arnab Goswami has said he was t...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "498be5c8-3de4-4765-8281-f5951e2e8f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = {'Headline': 'Summary', 'Short': 'News'}\n",
    "data = data.rename(new, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a877052-9363-4de7-9578-17fff936dbc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>News</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 ex-bank officials booked for cheating bank o...</td>\n",
       "      <td>The CBI on Saturday booked four former officia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Supreme Court to go paperless in 6 months: CJI</td>\n",
       "      <td>Chief Justice JS Khehar has said the Supreme C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>At least 3 killed, 30 injured in blast in Sylh...</td>\n",
       "      <td>At least three people were killed, including a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why has Reliance been barred from trading in f...</td>\n",
       "      <td>Mukesh Ambani-led Reliance Industries (RIL) wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Was stopped from entering my own studio at Tim...</td>\n",
       "      <td>TV news anchor Arnab Goswami has said he was t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55099</th>\n",
       "      <td>Sensex loses 400 points to hit 52-week low</td>\n",
       "      <td>Tracking weak cues from the Asian markets, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55100</th>\n",
       "      <td>China to inject $91 bn into the money markets</td>\n",
       "      <td>Amid growing concerns about China&amp;#39;s econom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55101</th>\n",
       "      <td>Ghulam Ali set to make acting debut in Bollywood</td>\n",
       "      <td>Pakistani Ghazal singer Ghulam Ali will soon m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55102</th>\n",
       "      <td>IS acknowledges death of Jihadi John: Report</td>\n",
       "      <td>The Islamic State (IS) has acknowledged the de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55103</th>\n",
       "      <td>Cairn to seek $600 mn from India in damages</td>\n",
       "      <td>UK-based oil firm Cairn Energy on Tuesday said...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55104 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Summary  \\\n",
       "0      4 ex-bank officials booked for cheating bank o...   \n",
       "1         Supreme Court to go paperless in 6 months: CJI   \n",
       "2      At least 3 killed, 30 injured in blast in Sylh...   \n",
       "3      Why has Reliance been barred from trading in f...   \n",
       "4      Was stopped from entering my own studio at Tim...   \n",
       "...                                                  ...   \n",
       "55099         Sensex loses 400 points to hit 52-week low   \n",
       "55100      China to inject $91 bn into the money markets   \n",
       "55101   Ghulam Ali set to make acting debut in Bollywood   \n",
       "55102       IS acknowledges death of Jihadi John: Report   \n",
       "55103        Cairn to seek $600 mn from India in damages   \n",
       "\n",
       "                                                    News  \n",
       "0      The CBI on Saturday booked four former officia...  \n",
       "1      Chief Justice JS Khehar has said the Supreme C...  \n",
       "2      At least three people were killed, including a...  \n",
       "3      Mukesh Ambani-led Reliance Industries (RIL) wa...  \n",
       "4      TV news anchor Arnab Goswami has said he was t...  \n",
       "...                                                  ...  \n",
       "55099  Tracking weak cues from the Asian markets, the...  \n",
       "55100  Amid growing concerns about China&#39;s econom...  \n",
       "55101  Pakistani Ghazal singer Ghulam Ali will soon m...  \n",
       "55102  The Islamic State (IS) has acknowledged the de...  \n",
       "55103  UK-based oil firm Cairn Energy on Tuesday said...  \n",
       "\n",
       "[55104 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d42a8177-3b7d-4d63-a47a-124bda1c347b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "data['Summary'] = data['Summary'].apply(lambda x: ' '+x+' ')\n",
    "#removing extra spaces\n",
    "data['News'] = data['News'].apply(lambda x: x.strip())\n",
    "data['Summary'] = data['Summary'].apply(lambda x: x.strip())\n",
    "#keeping only alphabets and numbers\n",
    "data['News'] = data['News'].apply(lambda x: re.sub(\"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\", \" \", x))\n",
    "data['Summary'] = data['Summary'].apply(lambda x: re.sub(\"@\\S+|https?:\\S+|http?:\\S|[^<>A-Za-z0-9]+\", \" \", x))\n",
    "#lower casing\n",
    "data['News'] = data['News'].apply(lambda x: x.lower())\n",
    "data['Summary'] = data['Summary'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e68fc872-50bc-42a2-bdfb-3ae0641c9b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsTokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='')\n",
    "summaryTokenizer = tf.keras.preprocessing.text.Tokenizer(filters=\"\", oov_token='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a15add7-c270-4fb8-b88a-8955bc1c68c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsTokenizer.fit_on_texts(data['News'])\n",
    "summaryTokenizer.fit_on_texts(data['Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c71c620-623d-4bc2-8b4a-0fd8913f7319",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = newsTokenizer.texts_to_sequences(data['News'])\n",
    "targets = summaryTokenizer.texts_to_sequences(data['Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d417f4e3-0824-455b-8480-438935d0ba18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News example:  chief justice js khehar has said the supreme court will go paperless in six to seven months in a bid to save funds and make the judiciary eco friendly he further said the apex court will collect all the records electronically from the lower courts and the high courts so that there is no need to file hard copies \n",
      "News to sequences:  [111, 989, 10808, 10809, 13, 16, 2, 353, 82, 20, 402, 14970, 5, 212, 3, 411, 338, 5, 7, 1463, 3, 1637, 868, 8, 195, 2, 6044, 4303, 2210, 27, 83, 16, 2, 2510, 82, 20, 3450, 74, 2, 990, 14297, 21, 2, 1472, 2631, 8, 2, 158, 2631, 249, 14, 153, 15, 152, 576, 3, 2186, 1719, 5171]\n",
      "\n",
      "Summary example:  supreme court to go paperless in 6 months cji\n",
      "Summary to sequences:  [1774, 168, 3, 221, 9593, 4, 72, 403, 3058]\n"
     ]
    }
   ],
   "source": [
    "print('News example: ', data['News'][1])\n",
    "print('News to sequences: ', inputs[1])\n",
    "print()\n",
    "print('Summary example: ', data['Summary'][1])\n",
    "print('Summary to sequences: ', targets[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4da88fdf-1e56-48aa-8032-d4facbf46020",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_vocab_size = len(newsTokenizer.word_index)+1\n",
    "summary_vocab_size = len(summaryTokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e71b74f6-f8b2-4a06-b4ea-f2287540788f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News vocabulary size:  68204\n",
      "Summary vocabulary size: 28282\n"
     ]
    }
   ],
   "source": [
    "print('News vocabulary size: ', news_vocab_size)\n",
    "print('Summary vocabulary size:', summary_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5dcd69e-375d-43d0-a435-2c01afb0e514",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting appropriate lens \n",
    "news_lengths = pd.Series([len(x) for x in data['News']])\n",
    "summary_lengths = pd.Series([len(x) for x in data['Summary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16985b4e-d2ef-41f3-8442-f4bf30d7afa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    55104.000000\n",
       "mean       358.166485\n",
       "std         24.743317\n",
       "min        213.000000\n",
       "25%        342.000000\n",
       "50%        359.000000\n",
       "75%        377.000000\n",
       "max        436.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_lengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63bc5af8-e93e-458f-afc7-6116b6baa1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    55104.000000\n",
       "mean        50.579849\n",
       "std          6.794609\n",
       "min          2.000000\n",
       "25%         46.000000\n",
       "50%         50.000000\n",
       "75%         56.000000\n",
       "max         74.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_lengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea8549b8-1c54-47ff-b095-9ab1b52680bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking values > and round figured to 75th percentile\n",
    "news_max_len = 400\n",
    "summary_max_len = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d68511f1-0aa3-40db-ae31-b6ebd5bd7a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=news_max_len, padding='post', truncating='post')\n",
    "padded_targets = tf.keras.preprocessing.sequence.pad_sequences(targets, maxlen=summary_max_len, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b08fc03-23bd-4896-bd59-f03ea8be20f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataset pipeline\n",
    "final_news_data = tf.cast(padded_inputs, dtype=tf.int32)\n",
    "final_summary_data = tf.cast(padded_targets, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c65a195-2e65-4038-aa44-9e18f499202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2d07de1-7041-43e6-9c7f-af8f09883c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((final_news_data, final_summary_data)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef48298-fc32-4ac5-a976-91daa2c5fce4",
   "metadata": {},
   "source": [
    "# BUILDING TRANSFORMER MODEL\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fdec7ad7-e3a8-482c-9b15-3e959483c5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#positional encoding\n",
    "def get_angles(position, i, d_model):\n",
    "    angle_rates = 1/np.power(10000, (2*(i//2))/np.float32(d_model))\n",
    "    return position*angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(\n",
    "        np.arange(position)[:, np.newaxis],\n",
    "        np.arange(d_model)[np.newaxis, :],\n",
    "        d_model)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb5648af-f609-404f-b2e3-cf2884677bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating padding for padded sequences\n",
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "#creating look ahead mask for masking future words from contributing in prediction of current words in self attention\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask\n",
    "\n",
    "#scaled dot product\n",
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63e50af5-c60b-4e26-8169-f9325bc28d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multi-head attention\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "        output = self.dense(concat_attention)\n",
    "            \n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "236cc16e-44d7-4379-8876-2361f59390ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feed-forward network\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),\n",
    "        tf.keras.layers.Dense(d_model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e7ff2f2-2c30-4ef6-9f18-9877fb812612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fundamental unit of transformer encoder\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "31bbb002-b3a8-460e-92c2-9754d0b34467",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fundamental unit of transformer decoder\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)\n",
    "\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93e36df5-e1bc-4aca-88ef-0de727add62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder having multiple encoder layers\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "    \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "650ad39d-d968-4552-a6ae-232a9bad39cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoder having multiple decoder layers\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "        return x, attention_weights\n",
    "\n",
    "\n",
    "#The Transformer\n",
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
    "\n",
    "        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "93b6e49a-3f05-4fc1-948f-6fd59ee5bf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper-parameter\n",
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4db56760-810d-48f4-88f9-56849380e966",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adam optimizer with custom learning rate scheduler\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, dtype=tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "82726345-8e08-4b9e-8b3a-2b8b4cbf382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "51d98a8b-ec8e-4542-ab72-ad79d02e8184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ingle\\anaconda3\\envs\\forgery\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:585: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#defining loss and loss function\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f86f7e69-4c98-4159-9ece-1394c9d55917",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers, \n",
    "    d_model, \n",
    "    num_heads, \n",
    "    dff,\n",
    "    news_vocab_size, \n",
    "    summary_vocab_size, \n",
    "    pe_input=news_vocab_size, \n",
    "    pe_target=summary_vocab_size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cea67ded-5166-4a01-965c-1b976f6a73a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating masks for training\n",
    "def create_masks(inp, tar):\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a6d6d4fd-aac9-4de3-a974-d7ef34b56850",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating checkpoints for saving model config and weights\n",
    "checkpoint_path = \"/content/gdrive/My Drive/Transformer/\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "56354fcd-cc90-40b3-8544-44cd77e3cffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training steps\n",
    "\n",
    "@tf.function\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(\n",
    "            inp, tar_inp, \n",
    "            True, \n",
    "            enc_padding_mask, \n",
    "            combined_mask, \n",
    "            dec_padding_mask\n",
    "        )\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    train_loss(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7108caf9-2072-47ef-9655-dc6f393ce2b5",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c734ec45-cd46-4bb2-8db9-0a5476d8450b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 10.2321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "  \n",
    "    for (batch, (inp, tar)) in enumerate(dataset):\n",
    "        train_step(inp, tar)\n",
    "    \n",
    "        if batch % 429 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, train_loss.result()))\n",
    "      \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
    "    \n",
    "    print ('Epoch {} Loss {:.4f}'.format(epoch + 1, train_loss.result()))\n",
    "\n",
    "    print ('Time taken for this epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65601373-3e72-48a1-82c2-f265da87b94d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
